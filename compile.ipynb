{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('Data.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arr_0\n",
      "arr_1\n",
      "arr_2\n",
      "arr_3\n",
      "arr_4\n"
     ]
    }
   ],
   "source": [
    "for p in data:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 10), (1000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,Y = data['arr_1'], data['arr_0']\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=2\n",
    "h=0.5\n",
    "\n",
    "def loggarma(X,Y,p,q,max_iter,t_0):\n",
    "    z = np.array([c]*Y.shape[0])\n",
    "    Y_1 = np.maximum(Y,z)\n",
    "    beta = [0]*(X.shape[1] - 1)\n",
    "    beta.insert(0,np.log(Y.sum()/Y.shape[0]))\n",
    "    beta = np.array(beta)\n",
    "    phi = np.random.rand(p).reshape(-1,1)\n",
    "    theta = np.random.rand(q).reshape(-1,1)\n",
    "    alpha = 1\n",
    "    eta = np.zeros([Y.shape[0],1])\n",
    "    deta_beta = np.zeros([Y.shape[0],beta.shape[0]])\n",
    "    deta_phi = np.zeros([Y.shape[0],p])\n",
    "    deta_theta = np.zeros([Y.shape[0],q])\n",
    "    deta_alpha = np.zeros([Y.shape[0],1])\n",
    "    deta_alpha[t_0]= 1./alpha\n",
    "    max_num = max(max(p,q),beta.shape[0])\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        #Save old values \n",
    "        dold_beta = deta_beta\n",
    "        dold_phi = deta_phi\n",
    "        dold_theta = deta_theta\n",
    "        dold_alpha = deta_alpha\n",
    "        eta_old = eta\n",
    "      \n",
    "        #calculate new values of eta\n",
    "        eta[:max_num] = np.log(Y[:max_num].reshape(-1,1))\n",
    "        eta[max_num:] = np.dot(X[max_num:,:],beta).reshape(-1,1)\n",
    "        eta[t_0] += np.log(alpha)\n",
    "\n",
    "        for j in range(X.shape[0] - max_num):\n",
    "            X_block_p = X[j:j + phi.shape[0],:].transpose()\n",
    "            Y_block_q = Y[j:j + theta.shape[0]]\n",
    "            Y_block_p = Y[j:j + phi.shape[0]]\n",
    "            eta_block_q = eta_old[j:j+theta.shape[0]]\n",
    "            \n",
    "#             print(np.flip(Y_block_p,axis=0).shape, 'sdasdsads', np.flip(X_block_p,axis=0).T.shape)\n",
    "            \n",
    "            phi_block = np.log(np.flip(Y_block_p,axis=0).reshape(-1,1)) - np.dot(np.flip(X_block_p,axis=0).T,beta).reshape(-1,1)\n",
    "            theta_block = np.log(np.flip(Y_block_q,axis=0).reshape(-1,1)) - eta_block_q\n",
    "            \n",
    "#             print(phi_block.T.shape, phi.T.shape, theta_block.T.shape)\n",
    "            eta[j + max_num] += (np.inner(phi_block.T,phi.T) + np.inner(theta_block.T,theta.T)).reshape(-1,)\n",
    "            \n",
    "        ##Check for convergence\n",
    "        \n",
    "##Update gradients\n",
    "        deta_beta = X[:,0:beta.shape[0]]\n",
    "        #np.inner(np.flip(phi1,axis=0).transpose(),a.transpose())\n",
    "        for j in range(X.shape[0] - phi.shape[0]):\n",
    "            X_block = X[j:j + phi.shape[0],:]\n",
    "\n",
    "            Y_block = Y[j:j+ phi.shape[0]]\n",
    "            deta_beta[j+phi.shape[0],:] -= (np.inner(np.flip(phi,axis=0).T, X_block.T).T).reshape(-1,)\n",
    "            deta_phi[j+phi.shape[0],:] = np.log(np.flip(Y_block,axis=0)) - np.dot(np.flip(X_block,axis=0),beta)\n",
    "\n",
    "\n",
    "        for j in range(X.shape[0] - theta.shape[0]):\n",
    "            # q-sized blocks of older gradients11\n",
    "            dbeta_block = dold_beta[j:j+theta.shape[0],:].transpose()\n",
    "            dphi_block = dold_phi[j:j+theta.shape[0],:].transpose()\n",
    "            dtheta_block = dold_theta[j:j+theta.shape[0],:].transpose()\n",
    "\n",
    "            # update after multiplying with current values of theta.\n",
    "            Y_block_q = Y[j:j + theta.shape[0]]\n",
    "            eta_block_q = eta[j:j + theta.shape[0]]\n",
    "            deta_theta[j+theta.shape[0],:] = np.log(Y_block_q) - np.flip(eta_block_q.T,axis=0)\n",
    "            deta_beta[j+theta.shape[0],:] -= (np.inner(np.flip(theta,axis=0).transpose(),dbeta_block).transpose()).reshape(-1)\n",
    "            deta_phi[j+theta.shape[0],:] -= (np.inner(np.flip(theta,axis=0).transpose(),dphi_block).transpose()).reshape(-1)\n",
    "            deta_theta[j+theta.shape[0],:] -= (np.inner(np.flip(theta,axis=0).transpose(),dtheta_block).transpose()).reshape(-1)\n",
    "        \n",
    "\n",
    "        deta_alpha = np.zeros([Y.shape[0],1])\n",
    "        deta_alpha[t_0]= 1./alpha\n",
    "            \n",
    "\n",
    "   \n",
    "#OLS minimization \n",
    "        mu = np.exp(eta)\n",
    "#         print( mu.shape)\n",
    "        R = np.dot(deta_beta,beta).reshape(-1,1) + np.dot(deta_phi,phi)+ np.dot(deta_theta,theta) + np.dot(deta_alpha,alpha)  + h*(Y.reshape(-1,1) - mu)*mu\n",
    "        X_R = np.concatenate((deta_beta,deta_phi,deta_theta,deta_alpha),axis = 1)\n",
    "        wls = sm.WLS(R,X_R,weights = mu)\n",
    "        \n",
    "        res_wls = wls.fit('qr')\n",
    "#         print('checicijic')\n",
    "        print(res_wls.params)\n",
    "        beta = res_wls.params[:beta.shape[0]]\n",
    "        phi = res_wls.params[beta.shape[0]:p+beta.shape[0]]\n",
    "        theta = res_wls.params[beta.shape[0]+p:beta.shape[0]+p+q]\n",
    "#         print(res_wls.params[-1].shape)\n",
    "        alpha = int(res_wls.params[-1])\n",
    "        \n",
    "    return alpha,beta,phi,theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robsr/.local/lib/python3.6/site-packages/ipykernel_launcher.py:82: RuntimeWarning: overflow encountered in exp\n",
      "/home/robsr/.local/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:690: RuntimeWarning: invalid value encountered in multiply\n",
      "  return np.sqrt(self.weights)[:, None]*X\n",
      "/home/robsr/.local/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:667: RuntimeWarning: invalid value encountered in true_divide\n",
      "  weights = weights / np.sum(weights) * nobs\n",
      "/home/robsr/.local/lib/python3.6/site-packages/numpy/core/_methods.py:28: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims, initial)\n",
      "/home/robsr/.local/lib/python3.6/site-packages/numpy/linalg/linalg.py:1794: RuntimeWarning: invalid value encountered in greater\n",
      "  return count_nonzero(S > tol, axis=-1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-127-7ade0febb681>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mphi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloggarma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt_0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-126-af89cd6364dc>\u001b[0m in \u001b[0;36mloggarma\u001b[0;34m(X, Y, p, q, max_iter, t_0)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres_wls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;31m#         print(res_wls.params[-1].shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_wls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mphi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot convert float NaN to integer"
     ]
    }
   ],
   "source": [
    "alpha,beta,phi,theta = loggarma(X,Y,p=2,q=4,max_iter=5,t_0=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1)\n"
     ]
    }
   ],
   "source": [
    "j=0\n",
    "phi = np.random.rand(2).reshape(-1,1)\n",
    "X_block = X[j:j + phi.shape[0],:]\n",
    "print(np.inner(np.flip(phi,axis=0).T, X_block.T).T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
