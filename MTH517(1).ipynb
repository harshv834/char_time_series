{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_spd_matrix\n",
    "N = 1000\n",
    "D = 2\n",
    "mu = np.random.uniform(-1, 1, D)\n",
    "Sigma = make_spd_matrix(D)\n",
    "#Sigma = Sigma + np.diag([1e09]*D)\n",
    "print(mu)\n",
    "print(Sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "39147fe78645c8057eec1ac718794e145f42b592"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "X = multivariate_normal.rvs(mu, Sigma, N)\n",
    "print(X)\n",
    "print(np.max(X), np.min(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "eaff30535ea94fea783cc68f4ffe8972c98bda0f"
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "P = 1; Q = 1\n",
    "t_o = randint(max(P, Q), N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d0625dc41c64b148fa2be7f4d481a370acb7ad9b"
   },
   "outputs": [],
   "source": [
    "Beta = np.random.uniform(-1, 1, D)\n",
    "Phi = np.random.uniform(-1, 1, P)\n",
    "Theta = np.random.uniform(-1, 1, Q)\n",
    "print(Beta)\n",
    "print(Phi)\n",
    "print(Theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "33fd1e828906b49a9a1abfffeaf18f39509ba619",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "alpha = 15\n",
    "t1 = []; t2 = []\n",
    "nu = list(np.random.uniform(0,2, max(P, Q)))\n",
    "Y = []\n",
    "for i in range(max(P, Q)):\n",
    "    x = np.random.poisson(np.exp(nu[i]))\n",
    "    while x==0:\n",
    "        x = np.random.poisson(np.exp(nu[i]))\n",
    "    Y.append(x)\n",
    "    t1.append(np.log(Y[i]) - np.dot(X[i], Beta))\n",
    "    t2.append(np.log(Y[i]) - nu[i])\n",
    " \n",
    "for i in range(max(P, Q), N):\n",
    "    nu_ = np.dot(X[i], Beta) + np.dot(Phi, t1[:(-P-1):-1]) + np.dot(Theta, t2[:(-Q-1):-1])\n",
    "    #print(np.exp(nu_))\n",
    "    nu.append(nu_)\n",
    "    try:\n",
    "        if i!=(t_o - 1):\n",
    "            x = np.random.poisson(np.exp(nu_))\n",
    "            while x==0:\n",
    "                x = np.random.poisson(np.exp(nu_))\n",
    "            Y.append(x)\n",
    "        else:\n",
    "            x = np.random.poisson(alpha*np.exp(nu_))\n",
    "            while x==0:\n",
    "                x = np.random.poisson(alpha*np.exp(nu[i]))\n",
    "            Y.append(x)\n",
    "\n",
    "        if i<(N-1):\n",
    "            t1.append(np.log(x) - np.dot(X[i+1], Beta))\n",
    "            t2.append(np.log(x) - nu_)\n",
    "    except:\n",
    "        break\n",
    "print(nu)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5fbb7a571603abdf254b60b0c415faf7f2c9e3a9"
   },
   "outputs": [],
   "source": [
    "def cal_eta(Beta, Phi, Theta, X, Y, mu):\n",
    "    \"\"\"\n",
    "    X -> Observed X matrix NxD\n",
    "    Y -> Observed Y\n",
    "    mu -> Initial values of mu\n",
    "    \"\"\"\n",
    "    P = len(Phi); Q = len(Theta)\n",
    "    N = X.shape[0]\n",
    "    mu = list(mu)\n",
    "    t1 = []; t2 = []\n",
    "    for i in range(max(P, Q)):\n",
    "        t1.append(np.log(Y[i]) - np.dot(X[i], Beta))\n",
    "        t2.append(np.log(Y[i]) - mu[i])\n",
    "    for i in range(max(P, Q), N):\n",
    "        mu_ = np.dot(X[i], Beta) + np.dot(Phi, t1[:(-P-1):-1]) + np.dot(Theta, t2[:(-Q-1):-1])\n",
    "        mu.append(mu_)\n",
    "        if i<(N-1):\n",
    "            t1.append(np.log(Y[i]) - np.dot(X[i+1], Beta))\n",
    "            t2.append(np.log(Y[i]) - mu_)\n",
    "    mu = np.array(mu)\n",
    "    return mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cabe9761deffe5fa2930b4d4e5bfed42d0032693"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import statsmodels.api as sm\n",
    "c=2\n",
    "h=0.5\n",
    "\n",
    "def loggarma(X,Y,p,q,max_iter,t_0):\n",
    "    z = np.array([c]*Y.shape[0])\n",
    "    Y_1 = np.maximum(Y,z)\n",
    "    beta = np.array([np.mean(Y)]*X.shape[1]) #np.random.uniform(-1, 1, X.shape[1])     #[0]*(X.shape[1] - 1)\n",
    "    #beta.insert(0,np.log(Y.sum()/Y.shape[0]))\n",
    "    beta = np.array(beta).reshape(-1, 1)\n",
    "    phi = np.random.uniform(-1, 1, p).reshape(-1, 1)\n",
    "    theta = np.random.uniform(-1, 1, q).reshape(-1, 1)\n",
    "    alpha = 12\n",
    "    eta = np.random.uniform(0,2, X.shape[0])\n",
    "   \n",
    "    deta_beta = np.random.rand(Y.shape[0],beta.shape[0])\n",
    "    deta_phi = np.random.rand(Y.shape[0],p)\n",
    "    deta_theta = np.random.rand(Y.shape[0],q)\n",
    "    deta_alpha = np.random.rand(Y.shape[0],1)\n",
    "    deta_alpha[t_0]= 1./alpha\n",
    "    max_num = max(p,q)\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        #Save old values \n",
    "        dold_beta = deta_beta\n",
    "        dold_phi = deta_phi\n",
    "        dold_theta = deta_theta\n",
    "        dold_alpha = deta_alpha\n",
    "        eta_old = eta\n",
    "      \n",
    "        #calculate new values of eta\n",
    "        print(X.shape)\n",
    "        print('check_X')\n",
    "        #eta[:max_num] = copy.deepcopy(np.log(Y[:max_num].reshape(-1,1)))\n",
    "        #eta[max_num:] = copy.deepcopy(np.dot(X[max_num:,:],beta).reshape(-1,1))\n",
    "        #print(eta)\n",
    "        eta = np.random.uniform(0,2, max(p, q))\n",
    "        eta  = cal_eta(Beta, Phi, Theta, X, Y, eta)\n",
    "        print('check')\n",
    "        \n",
    "        eta[t_0-1] += np.log(alpha)\n",
    "        \"\"\"\n",
    "        for j in range(X.shape[0] - max_num):\n",
    "            X_block_p = copy.deepcopy(X[j:j + phi.shape[0],:]).transpose()\n",
    "            Y_block_q = copy.deepcopy(Y[j:j + theta.shape[0]])\n",
    "            Y_block_p = copy.deepcopy(Y[j:j + phi.shape[0]])\n",
    "            eta_block_q = eta_old[j:j+theta.shape[0]]\n",
    "                        \n",
    "            phi_block = np.log(np.flip(Y_block_p,axis=0).reshape(-1,1)) - np.dot(np.flip(X_block_p,axis=0).T,beta).reshape(-1,1)\n",
    "            theta_block = np.log(np.flip(Y_block_q,axis=0).reshape(-1,1)) - eta_block_q\n",
    "            eta[j + max_num] += (np.inner(phi_block.T,phi.T) + np.inner(theta_block.T,theta.T)).reshape(-1,)\n",
    "        \"\"\"    \n",
    "        ##Check for convergence\n",
    "        #print(np.max(X), np.min(X))\n",
    "        print(eta.shape, \"eta\")\n",
    "##Update gradients\n",
    "        deta_beta = copy.deepcopy(X[:,0:beta.shape[0]])\n",
    "        for j in range(X.shape[0] - phi.shape[0]):\n",
    "            X_block = copy.deepcopy(X[j:j + phi.shape[0],:])\n",
    "\n",
    "            Y_block = copy.deepcopy(Y[j:j+ phi.shape[0]])\n",
    "            deta_beta[j+phi.shape[0],:] -= (np.inner(np.flip(phi,axis=0).T, X_block.T).T).reshape(-1,)\n",
    "            deta_phi[j+phi.shape[0],:] = np.log(np.flip(Y_block,axis=0)) - np.dot(np.flip(X_block,axis=0),beta)\n",
    "        print(np.max(X), np.min(X))\n",
    "        print('final_check')\n",
    "        for j in range(X.shape[0] - theta.shape[0]):\n",
    "            # q-sized blocks of older gradients11\n",
    "            dbeta_block = dold_beta[j:j+theta.shape[0],:].transpose()\n",
    "            dphi_block = dold_phi[j:j+theta.shape[0],:].transpose()\n",
    "            dtheta_block = dold_theta[j:j+theta.shape[0],:].transpose()\n",
    "\n",
    "            # update after multiplying with current values of theta.\n",
    "            Y_block_q = Y[j:j + theta.shape[0]]\n",
    "            eta_block_q = eta[j:j + theta.shape[0]]\n",
    "            deta_theta[j+theta.shape[0],:] = np.log(Y_block_q) - np.flip(eta_block_q.T,axis=0)\n",
    "            deta_beta[j+theta.shape[0],:] -= (np.inner(np.flip(theta,axis=0).transpose(),dbeta_block).transpose()).reshape(-1)\n",
    "            deta_phi[j+theta.shape[0],:] -= (np.inner(np.flip(theta,axis=0).transpose(),dphi_block).transpose()).reshape(-1)\n",
    "            deta_theta[j+theta.shape[0],:] -= (np.inner(np.flip(theta,axis=0).transpose(),dtheta_block).transpose()).reshape(-1)\n",
    "        \n",
    "        deta_alpha = np.zeros([Y.shape[0],1])\n",
    "        deta_alpha[t_0]= 1./alpha\n",
    "            \n",
    "   \n",
    "#OLS minimization\n",
    "        print(np.max(X), np.min(X))\n",
    "        print('check')\n",
    "        mu = np.exp(eta)\n",
    "        mu = np.clip(mu, 0.1,10e30)\n",
    "        \n",
    "        print(deta_beta.shape,deta_phi.shape,deta_theta.shape,deta_alpha.shape)\n",
    "        print(\"abcd\", beta.shape, phi.shape, theta.shape, alpha)\n",
    "        print(np.dot(deta_beta,beta).shape, np.dot(deta_phi,phi).shape, np.dot(deta_theta,theta).shape, np.dot(deta_alpha,alpha).shape)\n",
    "        print((h*(Y-mu)/(mu**0.5)).reshape(-1, 1).shape, \"shit\")\n",
    "        R = np.dot(deta_beta,beta) + np.dot(deta_phi,phi)+ np.dot(deta_theta,theta) + np.dot(deta_alpha,alpha) + (h*(Y - mu)/(mu**0.5)).reshape(-1, 1)\n",
    "                \n",
    "        X_R = np.concatenate((deta_beta,deta_phi,deta_theta,deta_alpha),axis = 1)\n",
    "        print(X_R.shape ,'X_R')\n",
    "        print(R.shape, \"R\")\n",
    "        print(mu.reshape.shape, \"mu\")\n",
    "        R = np.clip(R, -10e30,10e30)\n",
    "        X_R = np.clip(X_R, -10e30,10e30)\n",
    "        wls = sm.WLS(R,X_R,weights = mu)\n",
    "        res_wls = wls.fit('qr')\n",
    "        print(res_wls.params.shape, \"res\")\n",
    "        if (i+1)%10 == 0:\n",
    "            print('iteration: ', i)\n",
    "            print(res_wls.params.shape, \"wls\")\n",
    "            \n",
    "        if np.sum(np.isnan(res_wls.params)) == 0:\n",
    "            print(res_wls.params, \"res\")\n",
    "            \n",
    "            beta = copy.deepcopy(res_wls.params[beta.shape[0]:])\n",
    "            phi = copy.deepcopy(res_wls.params[beta.shape[0]:p+beta.shape[0]])\n",
    "            theta = copy.deepcopy(res_wls.params[beta.shape[0]+p:beta.shape[0]+p+q])\n",
    "            alpha = float(res_wls.params[-1])\n",
    "    #print(res_wls.params, \"res\")   \n",
    "    return beta,phi,theta, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b01603c38a26c9c53fb32f2a154dbf96b551a4cf"
   },
   "outputs": [],
   "source": [
    "Y = np.array(Y)\n",
    "print(np.min(X, axis = 0), np.max(X, axis = 0))\n",
    "beta, phi, theta, alpha = loggarma(X,Y,1,1,10,t_o)\n",
    "print(beta.shape, phi.shape, theta.shape, alpha,  \"aaa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7e1a4f758e4c7306e086c9806b86a4bb320492d8"
   },
   "outputs": [],
   "source": [
    "Y_f = np.array(Y)\n",
    "X_f = np.array(X)\n",
    "Beta_f = np.array(Beta)\n",
    "Phi_f = np.array(Phi)\n",
    "Theta_f = np.array(Theta)\n",
    "np.savez(\"Data.npz\", Y_f, X_f, Beta_f, Phi_f, Theta_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "71eab8554c542eb581890ef21d1c79f12895ca9d"
   },
   "outputs": [],
   "source": [
    "def cal_mu(Beta, Phi, Theta, X, Y, mu):\n",
    "    \"\"\"\n",
    "    X -> Observed X matrix NxD\n",
    "    Y -> Observed Y\n",
    "    mu -> Initial values of mu\n",
    "    \"\"\"\n",
    "    P = len(Phi); Q = len(Theta)\n",
    "    N = X.shape[0]\n",
    "    mu = list(mu)\n",
    "    t1 = []; t2 = []\n",
    "    for i in range(max(P, Q)):\n",
    "        t1.append(np.log(Y[i]) - np.dot(X[i], Beta))\n",
    "        t2.append(np.log(Y[i]) - mu[i])\n",
    "    for i in range(max(P, Q), N):\n",
    "        mu_ = np.dot(X[i], Beta) + np.dot(Phi, t1[:(-P-1):-1]) + np.dot(Theta, t2[:(-Q-1):-1])\n",
    "        mu.append(np.exp(mu_))\n",
    "        if i<(N-1):\n",
    "            t1.append(np.log(Y[i]) - np.dot(X[i+1], Beta))\n",
    "            t2.append(np.log(Y[i]) - mu_)\n",
    "    mu = np.array(mu)\n",
    "    return mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ab78f1815849ad32199d27923d68d138938a2385"
   },
   "outputs": [],
   "source": [
    "def cal_mu_Y(Beta, Phi, Theta, X, Y, mu):\n",
    "    \"\"\"\n",
    "    X -> Observed X matrix NxD\n",
    "    Y -> Only initial values: max(P, Q)\n",
    "    mu -> Initial values of mu\n",
    "    \"\"\"\n",
    "    P = len(Phi); Q = len(Theta)\n",
    "    N = X.shape[0]\n",
    "    mu = list(mu); Y = list(Y)\n",
    "    t1 = []; t2 = []\n",
    "    for i in range(max(P, Q)):\n",
    "        t1.append(np.log(Y[i]) - np.dot(X[i], Beta))\n",
    "        t2.append(np.log(Y[i]) - mu[i])\n",
    "    for i in range(max(P, Q), N):\n",
    "        mu_ = np.dot(X[i], Beta) + np.dot(Phi, t1[:(-P-1):-1]) + np.dot(Theta, t2[:(-Q-1):-1])\n",
    "        mu.append(np.exp(mu_))\n",
    "        x = np.random.poisson(np.exp(mu_))\n",
    "        while x==0:\n",
    "            x = np.random.poisson(np.exp(mu_))\n",
    "        Y.append(x)\n",
    "        if i<(N-1):\n",
    "            t1.append(np.log(Y[i]) - np.dot(X[i+1], Beta))\n",
    "            t2.append(np.log(Y[i]) - mu_)\n",
    "    Y = np.array(Y)\n",
    "    mu = np.array(mu)\n",
    "    return Y, mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/harshv834/char_time_series\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "434b59eede1bc670f81d121272757ccc20aedbf8"
   },
   "outputs": [],
   "source": [
    "mu = list(np.random.uniform(0,2, max(P, Q)))\n",
    "Y = []\n",
    "for i in range(max(P, Q)):\n",
    "    x = np.random.poisson(np.exp(nu[i]))\n",
    "    while x==0:\n",
    "        x = np.random.poisson(np.exp(nu[i]))\n",
    "    Y.append(x)\n",
    "Y, mu = cal_mu_Y(Beta, Phi, Theta, X, Y, mu)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a2626a3036c05364e31f0e9839cc49d50f8943af"
   },
   "outputs": [],
   "source": [
    "mu1 = cal_mu(Beta, Phi, Theta, X, Y, mu[:max(P, Q)])\n",
    "print(mu1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "143a2c363a94f9c4b8e3aa8894e70dedfd086edf"
   },
   "outputs": [],
   "source": [
    "def pearson_residual(Y, mu):\n",
    "    return (Y-mu)/(mu**0.5)\n",
    "k = int(N*0.05)\n",
    "pear_res = pearson_residual(Y, mu)\n",
    "A = np.absolute(pear_res).argsort()[:-k:-1]\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9b1fb1c7dc95d86ea8996e6b35abcaa866d2d9ae"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import statsmodels.api as sm\n",
    "c=2\n",
    "h=0.5\n",
    "\n",
    "def loggarma(X,Y,p,q,max_iter,t_0):\n",
    "    z = np.array([c]*Y.shape[0])\n",
    "    Y_1 = np.maximum(Y,z)\n",
    "    beta = [0]*(X.shape[1] - 1)\n",
    "    beta.insert(0,np.log(Y.sum()/Y.shape[0]))\n",
    "    beta = np.array(beta)\n",
    "    phi = np.random.rand(p).reshape(-1,1)\n",
    "    theta = np.random.rand(q).reshape(-1,1)\n",
    "    alpha = 1\n",
    "    eta = np.random.rand(Y.shape[0],1)\n",
    "    deta_beta = np.random.rand(Y.shape[0],beta.shape[0])\n",
    "    deta_phi = np.random.rand(Y.shape[0],p)\n",
    "    deta_theta = np.random.rand(Y.shape[0],q)\n",
    "    deta_alpha = np.random.rand(Y.shape[0],1)\n",
    "    deta_alpha[t_0]= 1./alpha\n",
    "    max_num = max(max(p,q),beta.shape[0])\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        #Save old values \n",
    "        dold_beta = deta_beta\n",
    "        dold_phi = deta_phi\n",
    "        dold_theta = deta_theta\n",
    "        dold_alpha = deta_alpha\n",
    "        eta_old = eta\n",
    "      \n",
    "        #calculate new values of eta\n",
    "        print(np.max(X), np.min(X))\n",
    "        print('check')\n",
    "        eta[:max_num] = np.log(Y[:max_num].reshape(-1,1))\n",
    "        eta[max_num:] = np.dot(X[max_num:,:],beta).reshape(-1,1)\n",
    "        print(np.max(X), np.min(X))\n",
    "        print('check')\n",
    "        \n",
    "        eta[t_0] += np.log(alpha)\n",
    "        \n",
    "        for j in range(X.shape[0] - max_num):\n",
    "            X_block_p = X[j:j + phi.shape[0],:].transpose()\n",
    "            Y_block_q = Y[j:j + theta.shape[0]]\n",
    "            Y_block_p = Y[j:j + phi.shape[0]]\n",
    "            eta_block_q = eta_old[j:j+theta.shape[0]]\n",
    "                        \n",
    "            phi_block = np.log(np.flip(Y_block_p,axis=0).reshape(-1,1)) - np.dot(np.flip(X_block_p,axis=0).T,beta).reshape(-1,1)\n",
    "            theta_block = np.log(np.flip(Y_block_q,axis=0).reshape(-1,1)) - eta_block_q\n",
    "            eta[j + max_num] += (np.inner(phi_block.T,phi.T) + np.inner(theta_block.T,theta.T)).reshape(-1,)\n",
    "            \n",
    "        ##Check for convergence\n",
    "        print(np.max(X), np.min(X))\n",
    "        print('check')\n",
    "##Update gradients\n",
    "        deta_beta = X[:,0:beta.shape[0]]\n",
    "        for j in range(X.shape[0] - phi.shape[0]):\n",
    "            X_block = X[j:j + phi.shape[0],:]\n",
    "\n",
    "            Y_block = Y[j:j+ phi.shape[0]]\n",
    "            deta_beta[j+phi.shape[0],:] -= (np.inner(np.flip(phi,axis=0).T, X_block.T).T).reshape(-1,)\n",
    "            deta_phi[j+phi.shape[0],:] = np.log(np.flip(Y_block,axis=0)) - np.dot(np.flip(X_block,axis=0),beta)\n",
    "        print(np.max(X), np.min(X))\n",
    "        print('final_check')\n",
    "        for j in range(X.shape[0] - theta.shape[0]):\n",
    "            # q-sized blocks of older gradients11\n",
    "            dbeta_block = dold_beta[j:j+theta.shape[0],:].transpose()\n",
    "            dphi_block = dold_phi[j:j+theta.shape[0],:].transpose()\n",
    "            dtheta_block = dold_theta[j:j+theta.shape[0],:].transpose()\n",
    "\n",
    "            # update after multiplying with current values of theta.\n",
    "            Y_block_q = Y[j:j + theta.shape[0]]\n",
    "            eta_block_q = eta[j:j + theta.shape[0]]\n",
    "            deta_theta[j+theta.shape[0],:] = np.log(Y_block_q) - np.flip(eta_block_q.T,axis=0)\n",
    "            deta_beta[j+theta.shape[0],:] -= (np.inner(np.flip(theta,axis=0).transpose(),dbeta_block).transpose()).reshape(-1)\n",
    "            deta_phi[j+theta.shape[0],:] -= (np.inner(np.flip(theta,axis=0).transpose(),dphi_block).transpose()).reshape(-1)\n",
    "            deta_theta[j+theta.shape[0],:] -= (np.inner(np.flip(theta,axis=0).transpose(),dtheta_block).transpose()).reshape(-1)\n",
    "        \n",
    "        deta_alpha = np.zeros([Y.shape[0],1])\n",
    "        deta_alpha[t_0]= 1./alpha\n",
    "            \n",
    "   \n",
    "#OLS minimization\n",
    "        print(np.max(X), np.min(X))\n",
    "        print('check')\n",
    "        mu = np.exp(eta)\n",
    "        mu = np.clip(mu, 0.1,10e30)\n",
    "        \n",
    "        print(max(mu), min(mu))\n",
    "        \n",
    "        R = np.dot(deta_beta,beta).reshape(-1,1) + np.dot(deta_phi,phi)+ np.dot(deta_theta,theta) + np.dot(deta_alpha,alpha)  + h*(Y.reshape(-1,1) - mu)*mu\n",
    "                \n",
    "        X_R = np.concatenate((deta_beta,deta_phi,deta_theta,deta_alpha),axis = 1)\n",
    "        \n",
    "        R = np.clip(R, -10e30,10e30)\n",
    "        X_R = np.clip(X_R, -10e30,10e30)\n",
    "        wls = sm.WLS(R,X_R,weights = mu, missing='drop')\n",
    "        res_wls = wls.fit('qr')\n",
    "        \n",
    "        if (i+1)%10 == 0:\n",
    "            print('iteration: ', i)\n",
    "            print(res_wls.params)\n",
    "            \n",
    "        if np.sum(np.isnan(res_wls.params)) == 0:\n",
    "            print(res_wls.params)\n",
    "            \n",
    "            beta = res_wls.params[:beta.shape[0]]\n",
    "            phi = res_wls.params[beta.shape[0]:p+beta.shape[0]]\n",
    "            theta = res_wls.params[beta.shape[0]+p:beta.shape[0]+p+q]\n",
    "            alpha = float(res_wls.params[-1])\n",
    "        \n",
    "    return beta,phi,theta, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e003cb8951b1b259faf99f23f1b207597082a18d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3f67b77a60c8843da2de5c60dec32dea938a67c3"
   },
   "outputs": [],
   "source": [
    "def Test_stat(Y, mu_o, mu_a):\n",
    "    \"\"\"\n",
    "    Y -> Value of Y at t_o\n",
    "    mu_o -> Value of mu of NULL model\n",
    "    mu_a -> Value of mu of Alternate model\n",
    "    \"\"\"\n",
    "    c = 0.0000001\n",
    "    a = np.array([max(mu_o[i] - mu_a[i], c) for i in range(len(Y))])\n",
    "    return -2*(mu_o - mu_a) + Y*np.log(a)\n",
    "Test = Test_stat(Y, mu_o, mu_a)\n",
    "print(Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9820c9bff9d6903e28bb42c40b00293a52724bc8"
   },
   "outputs": [],
   "source": [
    "M = 10\n",
    "Test_boot = []\n",
    "T_o = Test.argsort()[-1]\n",
    "for i in range(M):\n",
    "    mu = list(np.random.uniform(0,2, max(P, Q)))\n",
    "    Y = []\n",
    "    for i in range(max(P, Q)):\n",
    "        x = np.random.poisson(np.exp(nu[i]))\n",
    "        while x==0:\n",
    "            x = np.random.poisson(np.exp(nu[i]))\n",
    "        Y.append(x)\n",
    "    Y_boot, Mu_boot = cal_mu_Y(Beta, Phi, Theta, X, Y, mu)\n",
    "    Test_boot.append(Test_stat(Y_boot[T_o], Mu_boot[T_o], 1))\n",
    "print(Test_boot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
