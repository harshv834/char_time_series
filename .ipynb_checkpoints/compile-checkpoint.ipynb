{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('Data.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 10), (1000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,Y = data['arr_1'], data['arr_0']\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.163126627198914, -8.731256615900621)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(X), np.min(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=2\n",
    "h=0.5\n",
    "\n",
    "def loggarma(X,Y,p,q,max_iter,t_0):\n",
    "    z = np.array([c]*Y.shape[0])\n",
    "    Y_1 = np.maximum(Y,z)\n",
    "    beta = [0]*(X.shape[1] - 1)\n",
    "    beta.insert(0,np.log(Y.sum()/Y.shape[0]))\n",
    "    beta = np.array(beta)\n",
    "    phi = np.random.rand(p).reshape(-1,1)\n",
    "    theta = np.random.rand(q).reshape(-1,1)\n",
    "    alpha = 1\n",
    "    eta = np.random.rand(Y.shape[0],1)\n",
    "    deta_beta = np.random.rand(Y.shape[0],beta.shape[0])\n",
    "    deta_phi = np.random.rand(Y.shape[0],p)\n",
    "    deta_theta = np.random.rand(Y.shape[0],q)\n",
    "    deta_alpha = np.random.rand(Y.shape[0],1)\n",
    "    deta_alpha[t_0]= 1./alpha\n",
    "    max_num = max(max(p,q),beta.shape[0])\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        #Save old values \n",
    "        dold_beta = deta_beta\n",
    "        dold_phi = deta_phi\n",
    "        dold_theta = deta_theta\n",
    "        dold_alpha = deta_alpha\n",
    "        eta_old = eta\n",
    "      \n",
    "        #calculate new values of eta\n",
    "        eta[:max_num] = np.log(Y[:max_num].reshape(-1,1))\n",
    "        eta[max_num:] = np.dot(X[max_num:,:],beta).reshape(-1,1)\n",
    "        \n",
    "        eta[t_0] += np.log(alpha)\n",
    "        for j in range(X.shape[0] - max_num):\n",
    "            X_block_p = X[j:j + phi.shape[0],:].transpose().copy()\n",
    "            Y_block_q = Y[j:j + theta.shape[0]].copy()\n",
    "            Y_block_p = Y[j:j + phi.shape[0]].copy()\n",
    "            eta_block_q = eta_old[j:j+theta.shape[0]].copy()\n",
    "                        \n",
    "            phi_block = np.log(np.flip(Y_block_p,axis=0).reshape(-1,1)) - np.dot(np.flip(X_block_p,axis=0).T,beta).reshape(-1,1)\n",
    "            theta_block = np.log(np.flip(Y_block_q,axis=0).reshape(-1,1)) - eta_block_q\n",
    "            eta[j + max_num] += (np.inner(phi_block.T,phi.T) + np.inner(theta_block.T,theta.T)).reshape(-1,)\n",
    "            \n",
    "##Update gradients\n",
    "        deta_beta = X[:,0:beta.shape[0]].copy()\n",
    "        for j in range(X.shape[0] - phi.shape[0]):\n",
    "            X_block = X[j:j + phi.shape[0],:].copy()\n",
    "\n",
    "            Y_block = Y[j:j+ phi.shape[0]].copy()\n",
    "            \n",
    "            deta_beta[j+phi.shape[0],:] -= (np.inner(np.flip(phi,axis=0).T, X_block.T).T).reshape(-1,)\n",
    "\n",
    "            deta_phi[j+phi.shape[0],:] = np.log(np.flip(Y_block,axis=0)) - (np.dot(np.flip(X_block,axis=0),beta)).reshape(-1)\n",
    "    \n",
    "        for j in range(X.shape[0] - theta.shape[0]):\n",
    "            # q-sized blocks of older gradients11\n",
    "            dbeta_block = dold_beta[j:j+theta.shape[0],:].transpose().copy()\n",
    "            dphi_block = dold_phi[j:j+theta.shape[0],:].transpose().copy()\n",
    "            dtheta_block = dold_theta[j:j+theta.shape[0],:].transpose().copy()\n",
    "\n",
    "            # update after multiplying with current values of theta.\n",
    "            Y_block_q = Y[j:j + theta.shape[0]].copy()\n",
    "            eta_block_q = eta[j:j + theta.shape[0]].copy()\n",
    "            deta_theta[j+theta.shape[0],:] = np.log(Y_block_q) - np.flip(eta_block_q.T,axis=0)\n",
    "            deta_beta[j+theta.shape[0],:] -= (np.inner(np.flip(theta,axis=0).transpose(),dbeta_block).transpose()).reshape(-1)\n",
    "            deta_phi[j+theta.shape[0],:] -= (np.inner(np.flip(theta,axis=0).transpose(),dphi_block).transpose()).reshape(-1)\n",
    "            deta_theta[j+theta.shape[0],:] -= (np.inner(np.flip(theta,axis=0).transpose(),dtheta_block).transpose()).reshape(-1)\n",
    "        \n",
    "        deta_alpha = np.zeros([Y.shape[0],1])\n",
    "        deta_alpha[t_0]= 1./alpha\n",
    "            \n",
    "   \n",
    "#OLS minimization\n",
    "        mu = np.exp(eta)\n",
    "        mu = np.clip(mu, 0.1,10e30)\n",
    "        \n",
    "        \n",
    "        R = np.dot(deta_beta,beta).reshape(-1,1) + np.dot(deta_phi,phi)+ np.dot(deta_theta,theta) + np.dot(deta_alpha,alpha)  + h*(Y.reshape(-1,1) - mu)*mu\n",
    "        X_R = np.concatenate((deta_beta,deta_phi,deta_theta,deta_alpha),axis = 1)\n",
    "        \n",
    "        R = np.clip(R, -10e10,10e10)\n",
    "        X_R = np.clip(X_R, -10e10,10e10)\n",
    "#        wls = sm.WLS(R,X_R,weights = mu, missing='drop')\n",
    "#        res_wls = wls.fit('qr')\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_R,R,mu.reshape(-1))\n",
    "        params = (model.coef_).reshape(X_R.shape[1],1)\n",
    "        if (i+1)%10 == 0:\n",
    "            print('iteration: ', i)\n",
    "            print(model.coef_)\n",
    "            \n",
    "#        if np.sum(np.isnan(res_wls.params)) == 0:\n",
    "#            print(res_wls.params)\n",
    "            \n",
    "            beta = params[:beta.shape[0]]\n",
    "            phi = params[beta.shape[0]:p+beta.shape[0]]\n",
    "            theta = params[beta.shape[0]+p:beta.shape[0]+p+q]\n",
    "            print(params.shape)\n",
    "            alpha = float(params[-1])\n",
    "        \n",
    "    return beta,phi,theta,alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harshv834/anaconda3/envs/ml_def/lib/python3.6/site-packages/ipykernel_launcher.py:74: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  9\n",
      "[[-4.53631799e-18 -1.49528084e-18  2.15179042e-18 -1.80344642e-18\n",
      "   5.39420106e-18  7.58233612e-18  9.29592349e-18 -1.18788727e-18\n",
      "  -4.85844914e-18 -5.48636526e-18  3.75994400e-19 -1.34274931e-18\n",
      "  -4.74930689e-20 -6.06106549e-19  1.24033178e-18 -6.83057933e-19\n",
      "  -2.67036229e-47]]\n",
      "(17, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harshv834/anaconda3/envs/ml_def/lib/python3.6/site-packages/ipykernel_launcher.py:33: RuntimeWarning: invalid value encountered in log\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-29c7662c1e3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloggarma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt_0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-548d251fcaf0>\u001b[0m in \u001b[0;36mloggarma\u001b[0;34m(X, Y, p, q, max_iter, t_0)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;31m#        res_wls = wls.fit('qr')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_R\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_R\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[0;32m--> 482\u001b[0;31m                          y_numeric=True, multi_output=True)\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    571\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    572\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    574\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    451\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     42\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     43\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 44\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "beta, phi, theta, alpha = loggarma(X=X,Y=Y,p=2,q=4,max_iter=50,t_0=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
