{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_spd_matrix\n",
    "N = 1000\n",
    "D = 2\n",
    "mu = np.random.uniform(-1, 1, D)\n",
    "Sigma = make_spd_matrix(D)\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "X = multivariate_normal.rvs(mu, Sigma, N)\n",
    "\n",
    "from random import randint\n",
    "P = 1; Q = 1\n",
    "t_o = randint(max(P, Q), N)\n",
    "\n",
    "Beta = np.random.uniform(-1, 1, D)\n",
    "Phi = np.random.uniform(-1, 1, P)\n",
    "Theta = np.random.uniform(-1, 1, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 15\n",
    "t1 = []; t2 = []\n",
    "nu = list(np.random.uniform(0,2, max(P, Q)))\n",
    "Y = []\n",
    "for i in range(max(P, Q)):\n",
    "    x = np.random.poisson(np.exp(nu[i]))\n",
    "    while x==0:\n",
    "        x = np.random.poisson(np.exp(nu[i]))\n",
    "    Y.append(x)\n",
    "    t1.append(np.log(Y[i]) - np.dot(X[i], Beta))\n",
    "    t2.append(np.log(Y[i]) - nu[i])\n",
    " \n",
    "for i in range(max(P, Q), N):\n",
    "    nu_ = np.dot(X[i], Beta) + np.dot(Phi, t1[:(-P-1):-1]) + np.dot(Theta, t2[:(-Q-1):-1])\n",
    "    #print(np.exp(nu_))\n",
    "    nu.append(nu_)\n",
    "    try:\n",
    "        if i!=(t_o - 1):\n",
    "            x = np.random.poisson(np.exp(nu_))\n",
    "            while x==0:\n",
    "                x = np.random.poisson(np.exp(nu_))\n",
    "            Y.append(x)\n",
    "        else:\n",
    "            x = np.random.poisson(alpha*np.exp(nu_))\n",
    "            while x==0:\n",
    "                x = np.random.poisson(alpha*np.exp(nu[i]))\n",
    "            Y.append(x)\n",
    "\n",
    "        if i<(N-1):\n",
    "            t1.append(np.log(x) - np.dot(X[i+1], Beta))\n",
    "            t2.append(np.log(x) - nu_)\n",
    "    except:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_mu(Beta, Phi, Theta, X, Y, mu):\n",
    "    \"\"\"\n",
    "    X -> Observed X matrix NxD\n",
    "    Y -> Observed Y\n",
    "    mu -> Initial values of mu\n",
    "    \"\"\"\n",
    "    P = len(Phi); Q = len(Theta)\n",
    "    N = X.shape[0]\n",
    "    mu = list(mu)\n",
    "    t1 = []; t2 = []\n",
    "    for i in range(max(P, Q)):\n",
    "        t1.append(np.log(Y[i]) - np.dot(X[i], Beta))\n",
    "        t2.append(np.log(Y[i]) - mu[i])\n",
    "    for i in range(max(P, Q), N):\n",
    "        mu_ = np.dot(X[i], Beta) + np.dot(Phi, t1[:(-P-1):-1]) + np.dot(Theta, t2[:(-Q-1):-1])\n",
    "        mu.append(np.exp(mu_))\n",
    "        if i<(N-1):\n",
    "            t1.append(np.log(Y[i]) - np.dot(X[i+1], Beta))\n",
    "            t2.append(np.log(Y[i]) - mu_)\n",
    "    mu = np.array(mu)\n",
    "    return mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Downloads/params.pkl','rb') as f:\n",
    "    params = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  9\n",
      "[[-5.42683470e+05  8.21458109e+04 -2.03394509e+05 -6.14237040e+04\n",
      "   1.79563280e-01 -3.12096812e-02  2.35604494e-02  1.12837070e-02]]\n",
      "(8, 1)\n",
      "{'beta': array([[-542683.47018161],\n",
      "       [  82145.81089688]]), 'phi': array([[-203394.50866564],\n",
      "       [ -61423.70398896]]), 'theta': array([[ 0.17956328],\n",
      "       [-0.03120968],\n",
      "       [ 0.02356045],\n",
      "       [ 0.01128371]]), 'alpha': 1.0}\n",
      "iteration:  19\n",
      "[[ 5.22606140e-16 -7.91066999e-17 -1.95869571e-16 -5.91514372e-17\n",
      "  -1.22556744e-27 -2.30327913e-27 -1.67179118e-27 -9.36179308e-28]]\n",
      "(8, 1)\n",
      "{'beta': array([[ 5.22606140e-16],\n",
      "       [-7.91066999e-17]]), 'phi': array([[-1.95869571e-16],\n",
      "       [-5.91514372e-17]]), 'theta': array([[-1.22556744e-27],\n",
      "       [-2.30327913e-27],\n",
      "       [-1.67179118e-27],\n",
      "       [-9.36179308e-28]]), 'alpha': 1.0}\n",
      "iteration:  29\n",
      "[[-0.06011756  0.32995062  0.9839169   0.06868376 -0.14879971  0.63085093\n",
      "  -1.11011169  1.34512803]]\n",
      "(8, 1)\n",
      "{'beta': array([[-0.06011756],\n",
      "       [ 0.32995062]]), 'phi': array([[0.9839169 ],\n",
      "       [0.06868376]]), 'theta': array([[-0.14879971],\n",
      "       [ 0.63085093],\n",
      "       [-1.11011169],\n",
      "       [ 1.34512803]]), 'alpha': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:79: RuntimeWarning: invalid value encountered in subtract\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-f626f3269d31>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mphi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m \u001b[0mbeta0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphi0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheta0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloggarma_null\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt_0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-f626f3269d31>\u001b[0m in \u001b[0;36mloggarma_null\u001b[1;34m(X, Y, p, q, max_iter, t_0)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;31m#        res_wls = wls.fit('qr')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_R\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mR\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m         \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_R\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m10\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    480\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[1;32m--> 482\u001b[1;33m                          y_numeric=True, multi_output=True)\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    571\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[0;32m    572\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 573\u001b[1;33m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[0;32m    574\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    451\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[0;32m    452\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 453\u001b[1;33m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    454\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     42\u001b[0m             and not np.isfinite(X).all()):\n\u001b[0;32m     43\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[1;32m---> 44\u001b[1;33m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "#import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "c=2\n",
    "h=0.5\n",
    "\n",
    "def loggarma_null(X,Y,p,q,max_iter,t_0):\n",
    "    z = np.array([c]*Y.shape[0])\n",
    "    Y_1 = np.maximum(Y,z)\n",
    "    beta = [0]*(X.shape[1] - 1)\n",
    "    beta.insert(0,np.log(Y.sum()/Y.shape[0]))\n",
    "    beta = np.array(beta)\n",
    "    phi = np.random.rand(p).reshape(-1,1)\n",
    "    theta = np.random.rand(q).reshape(-1,1)\n",
    "    alpha = 1\n",
    "    eta = np.random.rand(Y.shape[0],1)\n",
    "    deta_beta = np.random.rand(Y.shape[0],beta.shape[0])\n",
    "    deta_phi = np.random.rand(Y.shape[0],p)\n",
    "    deta_theta = np.random.rand(Y.shape[0],q)\n",
    "    deta_alpha = np.zeros([Y.shape[0],1])\n",
    "    deta_alpha[t_0]= 0\n",
    "    max_num = max(max(p,q),beta.shape[0])\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        #Save old values \n",
    "        dold_beta = deta_beta\n",
    "        dold_phi = deta_phi\n",
    "        dold_theta = deta_theta\n",
    "        dold_alpha = deta_alpha\n",
    "        eta_old = eta\n",
    "      \n",
    "        #calculate new values of eta\n",
    "        eta[:max_num] = np.log(Y[:max_num].reshape(-1,1))\n",
    "        eta[max_num:] = np.dot(X[max_num:,:],beta).reshape(-1,1)\n",
    "        \n",
    "        eta[t_0] += np.log(1)\n",
    "        for j in range(X.shape[0] - max_num):\n",
    "            X_block_p = X[j:j + phi.shape[0],:].transpose().copy()\n",
    "            Y_block_q = Y[j:j + theta.shape[0]].copy()\n",
    "            Y_block_p = Y[j:j + phi.shape[0]].copy()\n",
    "            eta_block_q = eta_old[j:j+theta.shape[0]].copy()\n",
    "                        \n",
    "            phi_block = np.log(np.flip(Y_block_p,axis=0).reshape(-1,1)) - np.dot(np.flip(X_block_p,axis=0).T,beta).reshape(-1,1)\n",
    "            theta_block = np.log(np.flip(Y_block_q,axis=0).reshape(-1,1)) - eta_block_q\n",
    "            eta[j + max_num] += (np.inner(phi_block.T,phi.T) + np.inner(theta_block.T,theta.T)).reshape(-1,)\n",
    "            \n",
    "##Update gradients\n",
    "        deta_beta = X[:,0:beta.shape[0]].copy()\n",
    "        for j in range(X.shape[0] - phi.shape[0]):\n",
    "            X_block = X[j:j + phi.shape[0],:].copy()\n",
    "\n",
    "            Y_block = Y[j:j+ phi.shape[0]].copy()\n",
    "            \n",
    "            deta_beta[j+phi.shape[0],:] -= (np.inner(np.flip(phi,axis=0).T, X_block.T).T).reshape(-1,)\n",
    "\n",
    "            deta_phi[j+phi.shape[0],:] = np.log(np.flip(Y_block,axis=0)) - (np.dot(np.flip(X_block,axis=0),beta)).reshape(-1)\n",
    "    \n",
    "        for j in range(X.shape[0] - theta.shape[0]):\n",
    "            # q-sized blocks of older gradients11\n",
    "            dbeta_block = dold_beta[j:j+theta.shape[0],:].transpose().copy()\n",
    "            dphi_block = dold_phi[j:j+theta.shape[0],:].transpose().copy()\n",
    "            dtheta_block = dold_theta[j:j+theta.shape[0],:].transpose().copy()\n",
    "\n",
    "            # update after multiplying with current values of theta.\n",
    "            Y_block_q = Y[j:j + theta.shape[0]].copy()\n",
    "            eta_block_q = eta[j:j + theta.shape[0]].copy()\n",
    "            deta_theta[j+theta.shape[0],:] = np.log(Y_block_q) - np.flip(eta_block_q.T,axis=0)\n",
    "            deta_beta[j+theta.shape[0],:] -= (np.inner(np.flip(theta,axis=0).transpose(),dbeta_block).transpose()).reshape(-1)\n",
    "            deta_phi[j+theta.shape[0],:] -= (np.inner(np.flip(theta,axis=0).transpose(),dphi_block).transpose()).reshape(-1)\n",
    "            deta_theta[j+theta.shape[0],:] -= (np.inner(np.flip(theta,axis=0).transpose(),dtheta_block).transpose()).reshape(-1)\n",
    "        \n",
    "        deta_alpha = np.zeros([Y.shape[0],1])\n",
    "        deta_alpha[t_0]= 0\n",
    "            \n",
    "   \n",
    "#OLS minimization\n",
    "        mu = np.exp(eta)\n",
    "        mu = np.clip(mu, 0.1,10e30)\n",
    "        \n",
    "        \n",
    "        R = np.dot(deta_beta,beta).reshape(-1,1) + np.dot(deta_phi,phi)+ np.dot(deta_theta,theta)  + h*(Y.reshape(-1,1) - mu)*mu\n",
    "        X_R = np.concatenate((deta_beta,deta_phi,deta_theta),axis = 1)\n",
    "        \n",
    "        R = np.clip(R, -10e10,10e10)\n",
    "        X_R = np.clip(X_R, -10e10,10e10)\n",
    "#        wls = sm.WLS(R,X_R,weights = mu, missing='drop')\n",
    "#        res_wls = wls.fit('qr')\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_R,R,mu.reshape(-1))\n",
    "        params = (model.coef_).reshape(X_R.shape[1],1)\n",
    "        if (i+1)%10 == 0:\n",
    "            print('iteration: ', i)\n",
    "            print(model.coef_)\n",
    "            \n",
    "#        if np.sum(np.isnan(res_wls.params)) == 0:\n",
    "#            print(res_wls.params)\n",
    "            \n",
    "            beta = params[:beta.shape[0]]\n",
    "            phi = params[beta.shape[0]:p+beta.shape[0]]\n",
    "            theta = params[beta.shape[0]+p:beta.shape[0]+p+q]\n",
    "            print(params.shape)\n",
    "            alpha = float(1)\n",
    "            \n",
    "            saveDict = {'beta':beta, 'phi':phi, 'theta':theta, 'alpha':alpha}\n",
    "            print(saveDict)\n",
    "#             import pickle\n",
    "#             with open('params.pkl', 'wb') as f:\n",
    "#                 pickle.dump(f,saveDict)\n",
    "        \n",
    "    return beta,phi,theta,alpha\n",
    "beta0, phi0, theta0, alpha0 = loggarma_null(X=X,Y=Y,p=2,q=4,max_iter=50,t_0=50)\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "beta0, phi0, theta0, alpha0 = loggarma_null(X=X,Y=Y,p=2,q=4,max_iter=50,t_0=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_o = np.exp(np.array(nu[:max(P, Q)]))\n",
    "mu_o = cal_mu(Beta, Phi, Theta, X, Y, mu_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_residual(Y, mu):\n",
    "    return (Y-mu)/(mu**0.5)\n",
    "N = 100\n",
    "k = int(N*0.05)\n",
    "pear_res = pearson_residual(Y, mu_o)\n",
    "A = np.absolute(pear_res).argsort()[:-k:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=2\n",
    "h=0.5\n",
    "\n",
    "def loggarma(X,Y,p,q,max_iter,t_0):\n",
    "    z = np.array([c]*Y.shape[0])\n",
    "    Y_1 = np.maximum(Y,z)\n",
    "    beta = [0]*(X.shape[1] - 1)\n",
    "    beta.insert(0,np.log(Y.sum()/Y.shape[0]))\n",
    "    beta = np.array(beta)\n",
    "    phi = np.random.rand(p).reshape(-1,1)\n",
    "    theta = np.random.rand(q).reshape(-1,1)\n",
    "    alpha = 1\n",
    "    eta = np.random.rand(Y.shape[0],1)\n",
    "    deta_beta = np.random.rand(Y.shape[0],beta.shape[0])\n",
    "    deta_phi = np.random.rand(Y.shape[0],p)\n",
    "    deta_theta = np.random.rand(Y.shape[0],q)\n",
    "    deta_alpha = np.random.rand(Y.shape[0],1)\n",
    "    deta_alpha[t_0]= 1./alpha\n",
    "    max_num = max(max(p,q),beta.shape[0])\n",
    "\n",
    "    for i in range(max_iter):\n",
    "    #Save old values \n",
    "    dold_beta = deta_beta\n",
    "    dold_phi = deta_phi\n",
    "    dold_theta = deta_theta\n",
    "    dold_alpha = deta_alpha\n",
    "    eta_old = eta\n",
    "\n",
    "    #calculate new values of eta\n",
    "    eta[:max_num] = np.log(Y[:max_num].reshape(-1,1))\n",
    "    eta[max_num:] = np.dot(X[max_num:,:],beta).reshape(-1,1)\n",
    "\n",
    "    eta[t_0] += np.log(alpha)\n",
    "    for j in range(X.shape[0] - max_num):\n",
    "    X_block_p = X[j:j + phi.shape[0],:].transpose().copy()\n",
    "    Y_block_q = Y[j:j + theta.shape[0]].copy()\n",
    "    Y_block_p = Y[j:j + phi.shape[0]].copy()\n",
    "    eta_block_q = eta_old[j:j+theta.shape[0]].copy()\n",
    "\n",
    "    phi_block = np.log(np.flip(Y_block_p,axis=0).reshape(-1,1)) - np.dot(np.flip(X_block_p,axis=0).T,beta).reshape(-1,1)\n",
    "    theta_block = np.log(np.flip(Y_block_q,axis=0).reshape(-1,1)) - eta_block_q\n",
    "    eta[j + max_num] += (np.inner(phi_block.T,phi.T) + np.inner(theta_block.T,theta.T)).reshape(-1,)\n",
    "\n",
    "    ##Update gradients\n",
    "    deta_beta = X[:,0:beta.shape[0]].copy()\n",
    "    for j in range(X.shape[0] - phi.shape[0]):\n",
    "    X_block = X[j:j + phi.shape[0],:].copy()\n",
    "\n",
    "    Y_block = Y[j:j+ phi.shape[0]].copy()\n",
    "\n",
    "    deta_beta[j+phi.shape[0],:] -= (np.inner(np.flip(phi,axis=0).T, X_block.T).T).reshape(-1,)\n",
    "\n",
    "    deta_phi[j+phi.shape[0],:] = np.log(np.flip(Y_block,axis=0)) - (np.dot(np.flip(X_block,axis=0),beta)).reshape(-1)\n",
    "\n",
    "    for j in range(X.shape[0] - theta.shape[0]):\n",
    "    # q-sized blocks of older gradients11\n",
    "    dbeta_block = dold_beta[j:j+theta.shape[0],:].transpose().copy()\n",
    "    dphi_block = dold_phi[j:j+theta.shape[0],:].transpose().copy()\n",
    "    dtheta_block = dold_theta[j:j+theta.shape[0],:].transpose().copy()\n",
    "\n",
    "    # update after multiplying with current values of theta.\n",
    "    Y_block_q = Y[j:j + theta.shape[0]].copy()\n",
    "    eta_block_q = eta[j:j + theta.shape[0]].copy()\n",
    "    deta_theta[j+theta.shape[0],:] = np.log(Y_block_q) - np.flip(eta_block_q.T,axis=0)\n",
    "    deta_beta[j+theta.shape[0],:] -= (np.inner(np.flip(theta,axis=0).transpose(),dbeta_block).transpose()).reshape(-1)\n",
    "    deta_phi[j+theta.shape[0],:] -= (np.inner(np.flip(theta,axis=0).transpose(),dphi_block).transpose()).reshape(-1)\n",
    "    deta_theta[j+theta.shape[0],:] -= (np.inner(np.flip(theta,axis=0).transpose(),dtheta_block).transpose()).reshape(-1)\n",
    "\n",
    "    deta_alpha = np.zeros([Y.shape[0],1])\n",
    "    deta_alpha[t_0]= 1./alpha\n",
    "\n",
    "\n",
    "    #OLS minimization\n",
    "    mu = np.exp(eta)\n",
    "    mu = np.clip(mu, 0.1,10e30)\n",
    "\n",
    "\n",
    "    R = np.dot(deta_beta,beta).reshape(-1,1) + np.dot(deta_phi,phi)+ np.dot(deta_theta,theta) + np.dot(deta_alpha,alpha) + h*(Y.reshape(-1,1) - mu)*mu\n",
    "    X_R = np.concatenate((deta_beta,deta_phi,deta_theta,deta_alpha),axis = 1)\n",
    "\n",
    "    R = np.clip(R, -10e10,10e10)\n",
    "    X_R = np.clip(X_R, -10e10,10e10)\n",
    "    # wls = sm.WLS(R,X_R,weights = mu, missing='drop')\n",
    "    # res_wls = wls.fit('qr')\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_R,R,mu.reshape(-1))\n",
    "    params = (model.coef_).reshape(X_R.shape[1],1)\n",
    "    if (i+1)%10 == 0:\n",
    "    print('iteration: ', i)\n",
    "    print(model.coef_)\n",
    "\n",
    "    # if np.sum(np.isnan(res_wls.params)) == 0:\n",
    "    # print(res_wls.params)\n",
    "\n",
    "    beta = params[:beta.shape[0]]\n",
    "    phi = params[beta.shape[0]:p+beta.shape[0]]\n",
    "    theta = params[beta.shape[0]+p:beta.shape[0]+p+q]\n",
    "    print(params.shape)\n",
    "    alpha = float(params[-1])\n",
    "\n",
    "    saveDict = {'beta':beta, 'phi':phi, 'theta':theta, 'alpha':alpha}\n",
    "    print(saveDict)\n",
    "    return beta,phi,theta,alpha\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
